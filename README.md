# TSFool

TSFool is a tool for generating adversarial time series samples that can deceive Recurrent Neural Network (RNN) models.

## Main Features

1. Supports three types of automata: Finite State Machine (FSM), Nondeterministic Finite Automaton (NFA), and Weighted Finite Automaton (WFA).

2. Uses the k-Dimensional Confidence-Partition (k-DCP) method to abstract the hidden states of the model.

3. Generates adversarial samples using minimal positive samples, sensitive negative samples, approximate derivative of time series as weights, DBSCAN for clustering, and Simulated Annealing for optimization.

4. Provides a detailed evaluation of adversarial attacks, including the accuracy of the original model, the accuracy of the attacked model, the number of adversarial samples generated, the average time cost per sample, the average perturbation (expressed as a percentage), and the average disguise factor.

5. Provides data preprocessing functionality, supporting the UCR time series classification dataset.

## Code Files Description

- `main.py`: The main entry point of the project, which contains the main implementation of adversarial attacks.

- `FSM.py`: Implements the construction and operation of Finite State Machines (FSMs).

- `NFA.py`: Implements the construction and operation of Nondeterministic Finite Automata (NFAs).

- `WFA.py`: Implements the construction and operation of Weighted Finite Automata (WFAs).

- `evaluation.py`: Contains the evaluation function for adversarial attacks.

- `data preprocessing.py`: Implements data preprocessing functionality, used to read the UCR dataset and convert it into a format suitable for model use.

## Usage

1. First, run `data preprocessing.py` to preprocess the data.

2. Then, modify the parameters in `main.py` according to your needs and run it to perform adversarial attacks. You can choose which type of automaton to use, set the parameters for the k-DCP method, and set the parameters for adversarial sample generation.

3. Finally, you can run `evaluation.py` to evaluate the effects of adversarial attacks.

## Detailed Steps for Adversarial Sample Generation

The adversarial sample generation process in TSFool involves several steps:

1. **Identifying Sensitive Negative Samples and Target Positive Samples:** Sensitive negative samples are identified as the samples that are misclassified by the RNN model but correctly classified by the WFA. Target positive samples are selected from the samples that are correctly classified by both the RNN model and the WFA.

2. **Generating Minimal Positive Samples:** The minimal positive samples are generated by iteratively sampling between the sensitive negative samples and the target positive samples. The distance between the negative and positive samples is divided into 10 equal intervals, and samples are generated at each interval. The process continues until the difference between the negative and positive samples at each time step becomes smaller than the perturbation amount.

3. **Creating Random Mask Perturbations:** A random mask perturbation is applied to the minimal positive samples to generate adversarial samples. The perturbation amount is limited by the 'eps' parameter and is scaled according to the weights calculated from the approximate derivative of the time series.

4. **Optimizing Perturbations with Simulated Annealing:** Simulated annealing is used to find the optimal perturbation that can maximize the error rate of the RNN model. The initial temperature is set to a high value and gradually decreased according to the cooling rate. If the error rate does not improve for a certain number of iterations (determined by the 'patience' parameter), the iteration is stopped.

5. **Clustering Adversarial Samples with DBSCAN:** The DBSCAN algorithm is used to cluster the adversarial samples based on their Euclidean distance in the feature space. Only one sample is selected from each cluster to form the final set of adversarial samples.

## Main Function and Parameters

TSFool is implemented as a function in the `main.py` file. Below is a description of its parameters:

1. `model`: The RNN model you want to attack.

2. `X`: The time series data you want to attack. It's a NumPy array with the shape (sample_amount, time_step, feature_dim).

3. `Y`: The labels of the data. It's a NumPy array with the shape (sample_amount, ).

4. `automaton_type`: The type of automaton you want to use. In this project, you can choose 'WFA' (Weighted Finite Automaton), 'FSM' (Finite State Machine), or 'NFA' (Nondeterministic Finite Automaton).

5. `K`, `T`, `F`: Hyperparameters for building the automaton.

6. `eps`: A hyperparameter for perturbation, which denotes the perturbation amount under the limitation of 'micro'.

7. `N`, `P`, `C`: Hyperparameters for generating adversarial samples.

8. `target`: A hyperparameter for perturbation. -1 denotes untargeted attack, other values denote targeted attack with the corresponding label as the target.

9. `details`: If True, print the details of the attack process.

## Requirements

1. This project is implemented in Python, so you need to install Python and some necessary libraries, such as NumPy and PyTorch, on your computer.

2. Adversarial attacks may take some time to complete, depending on the complexity of your model, the size of your dataset, and the parameters you set.

## Contact

If you encounter any issues or want to get more detailed information, you can refer to the source code of the project or contact the author of the project.
